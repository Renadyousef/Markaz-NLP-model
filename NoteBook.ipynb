{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c887ed1b-00ef-4d27-8c0c-9fa8226148cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # 0 = first GPU, -1 = CPU for speed\n",
    "from arabert.preprocess import ArabertPreprocessor #preprocess text\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "load_dotenv()  # Loads HF_TOKEN automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b817fe54-7572-4c53-aa2b-f5d1794959af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da-pos-msa were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-msa-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#directly thro hugging face\n",
    "from transformers import pipeline\n",
    "\n",
    "# POS tagging\n",
    "pos = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"CAMeL-Lab/bert-base-arabic-camelbert-da-pos-msa\",\n",
    "    framework=\"pt\",\n",
    "    trust_remote_code=True  # VERY IMPORTANT\n",
    ")\n",
    "\n",
    "# NER\n",
    "ner = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-ner\",\n",
    "    framework=\"pt\",\n",
    "    trust_remote_code=True  # VERY IMPORTANT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1ffbe2-20dc-4fbc-9c4e-c1e785ca0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Arabic GPT3.5 for text generation to use in genrating other MQS options\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import openai  # <- this is required\n",
    "openai.api_key='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'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b102e3f-083e-4666-ab50-be97077a1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_text(entity, pos, word, sentence=None):\n",
    "    \"\"\"Generate natural Arabic question from entity + POS with more coverage and variety.\"\"\"\n",
    "    \n",
    "    # --- Person ---\n",
    "    if entity == \"PER\":\n",
    "        if pos in [\"noun\", \"noun_prop\"]:\n",
    "            return f\"من هو {word}؟\"\n",
    "        elif pos == \"adj\":\n",
    "            return f\"أي شخص وُصف بـ {word}؟\"\n",
    "        else:\n",
    "            return f\"إلى أي شخص تشير كلمة '{word}'؟\"\n",
    "    \n",
    "    # --- Location ---\n",
    "    if entity == \"LOC\":\n",
    "        return f\"أين تقع {word}؟\"\n",
    "    \n",
    "    # --- Organization ---\n",
    "    if entity == \"ORG\":\n",
    "        if pos == \"noun\":\n",
    "            return f\"ما هي المنظمة المسماة {word}؟\"\n",
    "        elif pos == \"adj\":\n",
    "            return f\"أي منظمة وُصفت بأنها {word}؟\"\n",
    "        else:\n",
    "            return f\"اذكر المنظمة المرتبطة بكلمة '{word}'؟\"\n",
    "    \n",
    "    # --- Date / Time ---\n",
    "    if entity in [\"DATE\", \"TIME\"]:\n",
    "        return f\"متى حدث ذلك؟ (الإشارة إلى {word})\"\n",
    "    \n",
    "    # --- Number / Quantity ---\n",
    "    if entity in [\"NUM\", \"QUANTITY\", \"PERCENT\"]:\n",
    "        return f\"ما هي القيمة العددية المذكورة: ____ (الإجابة {word})؟\"\n",
    "    \n",
    "    # --- Miscellaneous / Product / Event ---\n",
    "    if entity in [\"EVENT\", \"WORK_OF_ART\", \"MISC\"]:\n",
    "        return f\"إلى أي شيء يشير {word}؟\"\n",
    "    \n",
    "    # --- Default Cloze (fill-in-the-blank) ---\n",
    "    if sentence:\n",
    "        return f\"أكمل الفراغ: {sentence.replace(word, '____')}\"\n",
    "    \n",
    "    # --- Fallback ---\n",
    "    return f\"صف الكلمة: {word}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6832743-0714-442d-8677-17ed4a7b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "\n",
    "def generate_TF_question(sentence, entity_word, entity_type, ner_tags):\n",
    "    \"\"\"\n",
    "    Generate a True/False question using GPT-3.5 to make the False statement more natural.\n",
    "\n",
    "    sentence: the original sentence\n",
    "    entity_word: the correct entity in the sentence\n",
    "    entity_type: NER type, e.g., \"LOC\", \"PER\", \"ORG\"\n",
    "    ner_tags: output from ner() for the text\n",
    "    \"\"\"\n",
    "    # True statement\n",
    "    true_statement = f\"{sentence} (صح أم خطأ؟)\"\n",
    "\n",
    "    # Prepare prompt for GPT-3.5\n",
    "    prompt = f\"اجعل الجملة التالية خاطئة مع الحفاظ على المعنى العام والموضوع: {sentence}\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"أنت مساعد لإنشاء أسئلة صح أو خطأ باللغة العربية.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract generated text\n",
    "        false_sentence = response['choices'][0]['message']['content'].strip()\n",
    "        false_statement = false_sentence + \" (صح أم خطأ؟)\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error generating false statement:\", e)\n",
    "        # fallback: swap entity as before\n",
    "        other_entities = [tag['word'] for tag in ner_tags \n",
    "                          if tag['entity'] == entity_type and tag['word'] != entity_word]\n",
    "        distractor = random.choice(other_entities) if other_entities else entity_word + \"X\"\n",
    "        false_statement = sentence.replace(entity_word, distractor) + \" (صح أم خطأ؟)\"\n",
    "\n",
    "    # Randomly choose True or False\n",
    "    if random.choice([True, False]):\n",
    "        return {\"type\": \"TF\", \"statement\": true_statement, \"answer\": True}\n",
    "    else:\n",
    "        return {\"type\": \"TF\", \"statement\": false_statement, \"answer\": False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6fc1a6-cdf5-4861-88f6-43163e4a0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty_settings = {\n",
    "    \"easy\": {\n",
    "        \"num_questions\": 5,\n",
    "        \"tf_ratio\": 0.7,       # 70% TF, 30% MCQ\n",
    "        \"mcq_distractor_type\": \"simple\"  # simple placeholder distractors\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"num_questions\": 10,\n",
    "        \"tf_ratio\": 0.5,       # balanced\n",
    "        \"mcq_distractor_type\": \"medium\"  # some context-based distractors\n",
    "    },\n",
    "    \"hard\": {\n",
    "        \"num_questions\": 15,\n",
    "        \"tf_ratio\": 0.3,       # mostly MCQ\n",
    "        \"mcq_distractor_type\": \"challenging\"  # semantically close distractors\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5b543b-633f-4a39-8bee-e94195fd2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import openai\n",
    "\n",
    "def make_mq_options(entity_label, correct_entity, sentence, num_distractors=2):\n",
    "    \"\"\"\n",
    "    Generate MCQ options for a given entity using GPT-3.5 and the sentence context.\n",
    "    \n",
    "    entity_label: NER type of the correct entity (not used here but kept for compatibility)\n",
    "    correct_entity: the correct answer\n",
    "    sentence: full sentence containing the entity\n",
    "    num_distractors: number of distractors to generate\n",
    "    \"\"\"\n",
    "    distractors = []\n",
    "    prompt = (\n",
    "        f\"أعطني {num_distractors} كلمات عربية (كلمة واحدة فقط لكل بديل) \"\n",
    "        f\"تكون بدائل خاطئة لكلمة '{correct_entity}' في الجملة التالية: {sentence}. \"\n",
    "        f\"أجب فقط بالكلمات مفصولة بفاصلة.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"أنت مساعد لإنشاء خيارات متعددة الاختيار باللغة العربية.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract generated text\n",
    "        generated_text = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "        # Split by comma and clean\n",
    "        for option in generated_text.split(\"،\"):\n",
    "            option_clean = option.strip()\n",
    "            if option_clean and option_clean != correct_entity:\n",
    "                distractors.append(option_clean)\n",
    "\n",
    "        distractors = distractors[:num_distractors]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error generating distractors:\", e)\n",
    "        distractors = [f\"خيار{i+1}\" for i in range(num_distractors)]\n",
    "\n",
    "    # Combine correct answer + distractors and shuffle\n",
    "    options = distractors + [correct_entity]\n",
    "    random.shuffle(options)\n",
    "\n",
    "    return options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad85769-32b2-4889-a613-e7c723776079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MCQ_question(entity_word, sentence, entity_type=\"LOC\", full_text=None):\n",
    "    \"\"\"\n",
    "    Generate MCQ using entity as correct answer and GPT-3.5-generated distractors.\n",
    "    \"\"\"\n",
    "    # Generate the question text\n",
    "    question_text = generate_question_text(entity_type, \"noun\", entity_word, sentence)\n",
    "    \n",
    "    # Generate distractors using GPT-3.5\n",
    "    options = make_mq_options(entity_type, entity_word, sentence, num_distractors=2)\n",
    "    \n",
    "    return {\"type\": \"MCQ\", \"question\": question_text, \"options\": options, \"answer\": entity_word}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64de6e9d-42d9-4135-9b14-2139b15d37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def make_quiz(text, level=\"medium\"):\n",
    "    settings = difficulty_settings.get(level, difficulty_settings[\"medium\"])\n",
    "    num_questions = settings[\"num_questions\"]\n",
    "    tf_ratio = settings[\"tf_ratio\"]\n",
    "\n",
    "    questions = []\n",
    "    seen = set()\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Batch NER + POS once\n",
    "    ner_tags_all = ner(sentences, batch_size=32)\n",
    "    pos_tags_all = pos(sentences, batch_size=32)\n",
    "\n",
    "    for i, sentence in enumerate(tqdm(sentences)):\n",
    "        if len(questions) >= num_questions:\n",
    "            break\n",
    "        ner_tags = ner_tags_all[i]\n",
    "        pos_tags = pos_tags_all[i]\n",
    "        if not ner_tags:\n",
    "            continue\n",
    "\n",
    "        entity = ner_tags[0]\n",
    "        word = entity['word']\n",
    "        entity_type = entity['entity']\n",
    "        pos_tag = next((p['entity'] for p in pos_tags if p['word'] == word), \"noun\")\n",
    "\n",
    "        # TF vs MCQ decision\n",
    "        if random.random() < tf_ratio:\n",
    "            q = generate_TF_question(sentence, word, entity_type, ner_tags)\n",
    "        else:\n",
    "            q = generate_MCQ_question(word, sentence, entity_type, full_text=text)\n",
    "\n",
    "        # ensure no repeats\n",
    "        sig = (q[\"type\"], q.get(\"question\"), q.get(\"answer\"))\n",
    "        if sig not in seen:\n",
    "            questions.append(q)\n",
    "            seen.add(sig)\n",
    "\n",
    "    return questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a749261-5753-40e6-93fc-3a8490824221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. TF: \n",
      "تأسست جامعة الملك سعود في الرياض عام 1957. (صح أم خطأ؟) => True\n",
      "\n",
      "2. MCQ: أكمل الفراغ: كما تضم مدينة ____ العديد من المعالم السياحية الشهيرة.\n",
      "Options: ['دبي, القاهرة', 'أبوظبي'], Answer: أبوظبي\n",
      "\n",
      "3. TF: شركة أرامكو السعودية هي أصغر شركة نفط في العالم. (صح أم خطأ؟) => False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "تأسست جامعة الملك سعود في الرياض عام 1957. \n",
    "كما تضم مدينة أبوظبي العديد من المعالم السياحية الشهيرة.\n",
    "شركة أرامكو السعودية هي أكبر شركة نفط في العالم.\n",
    "\"\"\"\n",
    "# Generate a quiz at medium difficulty\n",
    "quiz = make_quiz(text, level=\"medium\")\n",
    "for i, q in enumerate(quiz, 1):\n",
    "    if q[\"type\"] == \"TF\":\n",
    "        print(f\"{i}. TF: {q['statement']} => {q['answer']}\")\n",
    "    elif q[\"type\"] == \"MCQ\":\n",
    "        print(f\"{i}. MCQ: {q['question']}\")\n",
    "        print(f\"Options: {q['options']}, Answer: {q['answer']}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529db0c2-bcc8-455f-8176-7fc2fb4f8170",
   "metadata": {},
   "source": [
    "\n",
    "Note:quality of question, quiz  must set question count how will it process long text and randomness of question no all same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b181fd-a95c-4fd9-bc79-a6b01ece5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def make_flashCards_chunk(sentences, window=5):\n",
    "    flashcards = []\n",
    "    used_terms = set()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        ner_tags = ner(sentence)\n",
    "        if not ner_tags:\n",
    "            continue\n",
    "        \n",
    "        main_entity = ner_tags[0]\n",
    "        entity_word = main_entity['word']\n",
    "        entity_type = main_entity['entity']\n",
    "        \n",
    "        # Skip if already used\n",
    "        if entity_word in used_terms:\n",
    "            continue\n",
    "        used_terms.add(entity_word)\n",
    "        \n",
    "        words = sentence.split()\n",
    "        try:\n",
    "            idx = words.index(entity_word)\n",
    "        except ValueError:\n",
    "            idx = 0\n",
    "        start = max(0, idx - window)\n",
    "        end = min(len(words), idx + window + 1)\n",
    "        definition = \" \".join([w for w in words[start:end] if w != entity_word])\n",
    "        \n",
    "        flashcards.append({\n",
    "            \"term\": entity_word,\n",
    "            \"definition\": definition.strip() or f\"نوع: {entity_type}\"\n",
    "        })\n",
    "    \n",
    "    return flashcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00410160-3df0-4184-9c49-018e27f9cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 'أبوظبي', 'definition': 'إمارة هي إحدى إمارات دولة الإمارات'}\n"
     ]
    }
   ],
   "source": [
    "text = \"إمارة أبوظبي هي إحدى إمارات دولة الإمارات العربية المتحدة السبع\"\n",
    "flashcards = make_flashCards(text, limit=5)\n",
    "\n",
    "for card in flashcards:\n",
    "    print(card)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee26d049-ba80-4356-b996-2bcb6707c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ Strategy for 30 max we do less pages we will need to chunck the request to model \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def make_quiz_from_large_text(text, level=\"medium\"):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = [sentences[i:i+200] for i in range(0, len(sentences), 200)]\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(make_quiz, \" \".join(chunk), level) for chunk in chunks]\n",
    "        for f in futures:\n",
    "            results.extend(f.result())\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14e70e46-9b73-4240-97d7-3199c69ffff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_text='''حشرجة الموت !\n",
    "الاحتضار\n",
    "كم سمعت بها قبل ان اسمعها . اما منذ تلك الليلة – ليلة العاشر من\n",
    "نيسان ) أبريل ( سنة -١٩٣١ فاني أكاد لا اسمع غيرها . اسمعها في دقات\n",
    "قلبي وفي انفاسي . اسمعها في صوتي وفي كل صوت اسمعها في همس النسائم\n",
    "وحفيف الأوراق . اسمعها في سكينة الليل وجلبة النهار .\n",
    "الا تباركت حياة تلتقي الآزال والآباد في لحظة منها فيندمج النقيض\n",
    "بالنقيض ، وتستوي الاضداد کالا نداد . تباركت لانك تهز أين بمقايس\n",
    "البشر . وفي هزئك قساوة . وفي قساوتك عدل . فلا تخجلين من ان تجمعي\n",
    "بين العرض والجوهر ، بين الهزل والجد ، بين المتاجر والمقابر ، بين حشرجة\n",
    "الموت وقرقعة التلفون !\n",
    "النهار الجمعة . والساعة نحو الخامسة والنصف انا استعد للانصراف من\n",
    "محل أنحر فيه كل يوم ساعات بكارى من حياتي لعدد محدود من مومسات\n",
    "الريالات ، وقلم اسمع حديثاً الا عن البيع والشراء ، عن الربح والخسارة ،\n",
    "عن سوق تصعد وسوق تهبط . يقرع جرس التلفون فيطلبونني اليه . اهو\n",
    "احد الزبائن يرغب في بضاعة او يشكو بضاعة او يعتذر عن عدم مقدرته\n",
    "على دفع ما عليه ؟\n",
    "نعم . انا هو . مرحباً . مرحباً ... ما ذا تقول و جبران ها و ... نعم\n",
    "في المستشفي ؟ «\n",
    "في مستشفى القديس فنسنت . وهو في غيبوبة . والطبيب لا يقدر\n",
    "انه يعيش حتى منتصف الليل . وليس حواليه احد من رفاقه وخلانه . فرأيت\n",
    "من واجبي ان اخبرك لعلي انك اقرب الناس اليه «\n",
    "☆☆☆\n",
    "تاكسي ! مستشفى القديس فنسفت - اسرع ايها السائق، اسرع «.\n",
    " على و كيف لهذا المسكين ان يسرع في شوارع مكتظة بالبشرية المسرعة\n",
    "اقدامها وعلى دواليبها والى اين يسرع هو لاء الناس - كل الى مستشفاه .\n",
    "و مستشفى الكل واحد .\n",
    "ومن هو هذا القديس فنسنت و بماذا تقدس حتى يقدس ليس بيني\n",
    "و بين مستشفاه غير ميل واقل من ميل . لكنه اطول ما قطعته في حياتي من\n",
    "المسافات - جبران على فراش الموت . أ أدركه حيا و اسرع ايها\n",
    "السائق ، اسرع\n",
    "انا اليوم رجل صحيح يا ميشا \" هذه آخر كلمات سمعتها منه وقد\n",
    "خاطبته بالتلفون قبل ذاك بايام مستفحصاً عن صحنه فتواعدنا ان نلتقي فنتعشى\n",
    "معا في احد المطاعم ونقضي السهرة عندي. وها انا ذاهب لأ تناول واياه العشاء\n",
    "على مائدة الموت في مطعم القديس فلسنت !\n",
    "انا اليوم رجل صحيح يا ميشا - انا غريب في هذا العالم العالم يا ميشا -\n",
    "انا احب هذا العالم يا ميشا « - الصحة والعلة . والموت والحياة . والوطن\n",
    "والغربة - ألا من يريني ما بينها من الفروق ؟\n",
    "اسرع ايها السائق . اسرع . في اية غرفة خليل جبران 9« - سوال اوجه الى رجل جالس الى\n",
    "مكتب قريب من الباب داخل المستشفى فيندفع يفحص تحت حرف\n",
    "الجيم « في قوائمه المنظمة كانه يفتش عن كلة في قاموس غير مبال ان\n",
    "صوت الرجل الذي يخاطبه يتهدج بصوت الموت\n",
    "ليس عندنا عليل بهذا الاسم يا سيدي . « واذ او كد له ان عندهم\n",
    "عليلاً اسمه جبران يحيلني الى رجل آخر عند مدخل المستشفى من شارع آخر\n",
    "فاخرج من حيث دخلت واسرع الى المدخل الذي ردني اليه . وهناك اعرف\n",
    "ان جبران في غرفة كذا في الطبقة الثالثة من تلك البناية المتعددة الطبقات .\n",
    "فاصعد سلالم كثيرة . وادور في منعرجات كثيرة . والفحص ابواباً كثيرة\n",
    "قبل ان اهتدي الى الباب الذي اطلبه . ووراء كل باب اقترب منه جسد\n",
    "يتكوى بالاوجاع ، وروح تحارب القدر . رباه . رباه . رباه ! هوذا\n",
    "جانب من خليقتك التي تطلب جابراً لما تكسر من عظامها . ورائقا لما نفتق\n",
    "من جلودها . وجامعاً لما تفتت من أكبادها . فلا تحصل الا على عقاقير ثم\n",
    "عقاقير . فأين دواوك و ام هو الالم مصهر المحبة - محبتك التي لا توصف .\n",
    "و سبيل الخلاص - خلاصك الذي لا يثمن ؟\n",
    "راهبات بمررن بي وامر بهن كانهن خیالات من عالم لا اعرفه . وفي\n",
    "سواد اثوابين ما يسود القلب . وممرضات\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cca2f8d6-55c6-4134-92c2-f2a112651826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 69/71 [00:10<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming make_quiz_from_large_text is already defined as you posted\n",
    "quiz = make_quiz_from_large_text(large_text, level=\"medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3b7aa02-d1e5-49f0-a640-887c3307563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MCQ: أكمل الفراغ: والساعة نحو الخامسة والنصف انا استعد للانصراف من\n",
      "محل أنحر فيه كل يوم ساعات بكارى من حياتي لعدد محدود من مومسات\n",
      "____ات ، وقلم اسمع حديثاً الا عن البيع والشراء ، عن الربح والخسارة ،\n",
      "عن سوق تصعد وسوق تهبط .\n",
      "Options: ['نقود, عملة', 'الريال'], Answer: الريال\n",
      "\n",
      "2. MCQ: أكمل الفراغ: مرحباً ... ما ذا تقول و ____ ها و ... نعم\n",
      "في المستشفي ؟ «\n",
      "في مستشفى القديس فنسنت .\n",
      "Options: ['جبران', 'مرحباً, زيد, ما ذا تقول, رامي, جبران, ها و, علي, نعم.'], Answer: جبران\n",
      "\n",
      "3. TF: مستشفى القديس فنسفت - اسرع ايها السائق، اسرع «. (صح أم خطأ؟) => True\n",
      "\n",
      "4. MCQ: أكمل الفراغ: وها انا ذاهب لأ تناول واياه العشاء\n",
      "على مائدة الموت في مطعم القديس ____نت !\n",
      "Options: ['فليس, فلان', 'فلس'], Answer: فلس\n",
      "\n",
      "5. MCQ: أكمل الفراغ: انا اليوم رجل صحيح يا ____ا - انا غريب في هذا العالم العالم يا ____ا -\n",
      "انا احب هذا العالم يا ____ا « - الصحة والعلة .\n",
      "Options: ['ميش', 'شخص, عامر'], Answer: ميش\n",
      "\n",
      "6. MCQ: أكمل الفراغ: في اية غرفة ____ جبران 9« - سوال اوجه الى رجل جالس الى\n",
      "مكتب قريب من الباب داخل المستشفى فيندفع يفحص تحت حرف\n",
      "الجيم « في قوائمه المنظمة كانه يفتش عن كلة في قاموس غير مبال ان\n",
      "صوت الرجل الذي يخاطبه يتهدج بصوت الموت\n",
      "ليس عندنا عليل بهذا الاسم يا سيدي .\n",
      "Options: ['صديق, صاحب', 'خليل'], Answer: خليل\n",
      "\n",
      "7. TF: واذا كنت أو كدت أنهم عندهم عليلاً اسمه جبران يحيلني إلى رجل آخر عند (صح أم خطأ؟) => False\n",
      "\n",
      "8. MCQ: أكمل الفراغ: وهناك اعرف\n",
      "ان ____ في غرفة كذا في الطبقة الثالثة من تلك البناية المتعددة الطبقات .\n",
      "Options: ['جبريل, جبروت', 'جبران'], Answer: جبران\n",
      "\n",
      "9. MCQ: أكمل الفراغ: اشكر ____ لانك ههنا .\n",
      "Options: ['الله', 'الشمس, القمر'], Answer: الله\n",
      "\n",
      "10. MCQ: أكمل الفراغ: فيقيت افكر\n",
      "بواسطة اتوصل بها اليك الى ان خطر لي - و كان ذلك الهاما ربانيا - ان\n",
      "اتلفن الي ادارة مجلة ) ____ السوري « لتطلعك على الامر .\n",
      "Options: ['الكلمتان البستنان هما: الكون', 'العالم', 'الكرة الأرضية.'], Answer: العالم\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first 20 questions for sanity check\n",
    "for i, q in enumerate(quiz[:20], 1):\n",
    "    if q[\"type\"] == \"TF\":\n",
    "        print(f\"{i}. TF: {q['statement']} => {q['answer']}\")\n",
    "    elif q[\"type\"] == \"MCQ\":\n",
    "        print(f\"{i}. MCQ: {q['question']}\")\n",
    "        print(f\"Options: {q['options']}, Answer: {q['answer']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fdfc7dc-1f7a-4d07-ba2a-aa8d9bee3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flashCards_large_text(text, window=5, max_flashcards=None, max_workers=4):#optmizing for larger text\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = [sentences[i:i+200] for i in range(0, len(sentences), 200)]\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(make_flashCards_chunk, chunk, window) for chunk in chunks]\n",
    "        for f in futures:\n",
    "            results.extend(f.result())\n",
    "    \n",
    "    # Optionally limit total flashcards\n",
    "    if max_flashcards:\n",
    "        results = results[:max_flashcards]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6799f66a-b7ab-459c-af0d-422193688bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 'الريال', 'definition': 'والساعة نحو الخامسة والنصف انا استعد'}\n",
      "{'term': 'جبران', 'definition': '... ما ذا تقول و ها و ... نعم في'}\n",
      "{'term': 'القديس', 'definition': 'مستشفى فنسفت - اسرع ايها السائق،'}\n",
      "{'term': 'فن', 'definition': 'ومن هو هذا القديس فنسنت و'}\n",
      "{'term': 'ميش', 'definition': 'أ أدركه حيا و اسرع ايها'}\n",
      "{'term': 'فلس', 'definition': 'وها انا ذاهب لأ تناول واياه'}\n",
      "{'term': 'خليل', 'definition': 'في اية غرفة جبران 9« - سوال اوجه'}\n",
      "{'term': 'الله', 'definition': 'بدها تتنهد وتقول : اشكر .'}\n",
      "{'term': 'العالم', 'definition': 'اتلفن الي ادارة مجلة ) السوري « لتطلعك على الامر'}\n"
     ]
    }
   ],
   "source": [
    "# Using the previous large_text\n",
    "flashcards = make_flashCards_large_text(large_text, window=5, max_flashcards=100)\n",
    "\n",
    "for card in flashcards[:20]:  # show first 20 flashcards\n",
    "    print(card)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027665e-aec9-47b0-9d83-b7680848224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "i think we need preproccesing for wired character parsing?\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
